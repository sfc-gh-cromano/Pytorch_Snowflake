{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorch Training Framework Tutorial\n",
        "\n",
        "This notebook demonstrates how to use the PyTorch training framework with Lightning and Hydra for end-to-end machine learning workflows.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The framework provides:\n",
        "- **Hydra Configuration Management**: Flexible configuration system for experiments\n",
        "- **Lightning Integration**: Scalable training with PyTorch Lightning\n",
        "- **Model Zoo**: Pre-built models and data modules\n",
        "- **Experiment Tracking**: Built-in logging and monitoring\n",
        "\n",
        "We'll walk through a complete CIFAR-10 classification example.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "First, let's import the necessary libraries and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import lightning as L\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Add the source directory to Python path\n",
        "project_root = Path.cwd().parent\n",
        "src_path = project_root / \"src\"\n",
        "sys.path.append(str(src_path))\n",
        "\n",
        "# Import our framework components\n",
        "from tfh_train.model_zoo.cifar_clf.model import CifarClassifier\n",
        "from tfh_train.model_zoo.cifar_clf.data_module import CifarClassifierLightningDataModule\n",
        "from tfh_train.model_zoo.cifar_clf.model_module import CifarClassifierTraining\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Lightning version: {L.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Understanding the Model Architecture\n",
        "\n",
        "Let's examine the CIFAR-10 classifier model that's included in the framework.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an instance of the model\n",
        "model = CifarClassifier()\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Test with a sample input\n",
        "sample_input = torch.randn(1, 3, 32, 32)  # CIFAR-10 image size\n",
        "with torch.no_grad():\n",
        "    output = model(sample_input)\n",
        "print(f\"\\nInput shape: {sample_input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Output (logits): {output}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Exploration\n",
        "\n",
        "Let's set up the data module and explore the CIFAR-10 dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CIFAR-10 class names\n",
        "cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Create data module\n",
        "data_module = CifarClassifierLightningDataModule(\n",
        "    batch_size=32,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Setup the data module\n",
        "data_module.setup(stage=\"fit\")\n",
        "\n",
        "print(f\"Training dataset size: {len(data_module.train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(data_module.validation_dataset)}\")\n",
        "print(f\"Test dataset size: {len(data_module.test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some sample images\n",
        "def imshow(img, title=None):\n",
        "    \"\"\"Display image with denormalization.\"\"\"\n",
        "    img = img * 0.5 + 0.5  # Denormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "# Get a batch of training data\n",
        "train_loader = data_module.train_dataloader()\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "for i in range(8):\n",
        "    ax = axes[i//4, i%4]\n",
        "    ax.imshow(np.transpose((images[i] * 0.5 + 0.5).numpy(), (1, 2, 0)))\n",
        "    ax.set_title(f'Class: {cifar10_classes[labels[i]]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Batch shape: {images.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "print(f\"Image range: [{images.min():.3f}, {images.max():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setting Up the Lightning Module\n",
        "\n",
        "Now let's create the Lightning module that wraps our model with training logic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import functools\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create the model\n",
        "model = CifarClassifier()\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer (using functools.partial as expected by the framework)\n",
        "optimizer_partial = functools.partial(optim.Adam, lr=0.001)\n",
        "\n",
        "# Create the Lightning module\n",
        "lightning_module = CifarClassifierTraining(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_partial\n",
        ")\n",
        "\n",
        "print(\"Lightning module created successfully!\")\n",
        "print(f\"Model: {type(lightning_module.neural_net).__name__}\")\n",
        "print(f\"Criterion: {type(lightning_module.criterion).__name__}\")\n",
        "print(f\"Optimizer: {optimizer_partial.func.__name__}\")\n",
        "\n",
        "# Note: The Lightning module now includes a forward() method that delegates to the underlying model\n",
        "# This allows direct inference: lightning_module(input_tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training the Model\n",
        "\n",
        "Let's train our model using PyTorch Lightning trainer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up trainer\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=3,  # Keep it short for demo\n",
        "    accelerator=\"auto\",  # Use GPU if available\n",
        "    devices=1,\n",
        "    logger=True,  # Enable default logger\n",
        "    enable_checkpointing=True,\n",
        "    enable_progress_bar=True,\n",
        "    log_every_n_steps=50\n",
        ")\n",
        "\n",
        "print(f\"Trainer configured:\")\n",
        "print(f\"  Max epochs: {trainer.max_epochs}\")\n",
        "print(f\"  Accelerator: {trainer.accelerator}\")\n",
        "print(f\"  Devices: {trainer.num_devices}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(\"Starting training...\")\n",
        "trainer.fit(lightning_module, data_module)\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Evaluation\n",
        "\n",
        "Let's evaluate our trained model on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_results = trainer.test(lightning_module, data_module)\n",
        "print(\"Test Results:\")\n",
        "for key, value in test_results[0].items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Making Predictions\n",
        "\n",
        "Let's use our trained model to make predictions on some test images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set model to evaluation mode\n",
        "lightning_module.eval()\n",
        "\n",
        "# Get a batch of test data\n",
        "test_loader = data_module.test_dataloader()\n",
        "test_iter = iter(test_loader)\n",
        "test_images, test_labels = next(test_iter)\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    outputs = lightning_module(test_images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    probabilities = F.softmax(outputs, dim=1)\n",
        "\n",
        "# Visualize predictions\n",
        "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
        "for i in range(8):\n",
        "    ax = axes[i//4, i%4]\n",
        "    \n",
        "    # Display image\n",
        "    img = test_images[i] * 0.5 + 0.5  # Denormalize\n",
        "    ax.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
        "    \n",
        "    # Add prediction info\n",
        "    true_class = cifar10_classes[test_labels[i]]\n",
        "    pred_class = cifar10_classes[predicted[i]]\n",
        "    confidence = probabilities[i][predicted[i]].item()\n",
        "    \n",
        "    color = 'green' if predicted[i] == test_labels[i] else 'red'\n",
        "    ax.set_title(f'True: {true_class}\\nPred: {pred_class}\\nConf: {confidence:.2f}', \n",
        "                color=color, fontsize=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate accuracy for this batch\n",
        "correct = (predicted == test_labels).sum().item()\n",
        "total = test_labels.size(0)\n",
        "batch_accuracy = 100 * correct / total\n",
        "print(f\"Batch accuracy: {batch_accuracy:.2f}% ({correct}/{total})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Next Steps\n",
        "\n",
        "Congratulations! You've successfully completed an end-to-end machine learning workflow using the PyTorch training framework.\n",
        "\n",
        "### What we accomplished:\n",
        "\n",
        "1. ‚úÖ **Explored the framework structure** - Understanding the modular design\n",
        "2. ‚úÖ **Loaded and visualized data** - Working with CIFAR-10 dataset  \n",
        "3. ‚úÖ **Trained a model** - Using PyTorch Lightning for scalable training\n",
        "4. ‚úÖ **Evaluated performance** - Analyzing results with metrics and visualizations\n",
        "5. ‚úÖ **Made predictions** - Using the trained model for inference\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Experiment with hyperparameters**: Modify learning rate, batch size, architecture\n",
        "2. **Try different optimizers**: SGD, AdamW, etc.\n",
        "3. **Add data augmentation**: Improve model generalization\n",
        "4. **Implement callbacks**: Early stopping, learning rate scheduling\n",
        "5. **Scale to multiple GPUs**: Use Lightning's distributed training features\n",
        "6. **Create custom models**: Add your own architectures to the model zoo\n",
        "7. **Experiment tracking**: Integrate with MLflow, Weights & Biases\n",
        "\n",
        "### Framework Commands:\n",
        "\n",
        "You can also use the framework from the command line:\n",
        "\n",
        "```bash\n",
        "# Train with default config\n",
        "tfh-train\n",
        "\n",
        "# Train with specific experiment\n",
        "tfh-train experiment=cifar_clf/cifar_clf_training\n",
        "\n",
        "# Override specific parameters\n",
        "tfh-train trainer.max_epochs=20 data_module.batch_size=64\n",
        "\n",
        "# Evaluate a trained model\n",
        "tfh-evaluate ckpt_path=/path/to/checkpoint.ckpt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary statistics\n",
        "print(\"üéâ Tutorial Complete!\")\n",
        "print(f\"üìä Final Test Accuracy: {test_results[0].get('test_Accuracy', 'N/A'):.4f}\")\n",
        "print(f\"üèóÔ∏è  Model Parameters: {trainable_params:,}\")\n",
        "print(f\"üìö Dataset Size: {len(data_module.train_dataset):,} training samples\")\n",
        "print(f\"‚ö° Framework: PyTorch Lightning + Hydra\")\n",
        "print(f\"üöÄ Ready for production scaling!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
